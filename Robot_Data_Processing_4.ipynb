{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Robot - Data Processing 4",
      "provenance": [],
      "collapsed_sections": [
        "naepyOndYxtt"
      ],
      "authorship_tag": "ABX9TyPpabbrRRX2JM4FQ/75p2Mw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moajjem04/Pytorch_Practice/blob/main/Robot_Data_Processing_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8qKGEwzgixm"
      },
      "source": [
        "# Accessing Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXY6FMlJgedd",
        "outputId": "f8bffb05-81dc-4adf-dfa8-7a000169729a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgKVXwzUgop4",
        "outputId": "25b5b78f-3b17-4f69-b89c-1993c59857ca"
      },
      "source": [
        "%cd '/content/drive/MyDrive/robot'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1xoj4fkjFWbgZZGpDNuTyZsH1-eOzncVi/robotic arm data - s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LOZbAmWtgqWE",
        "outputId": "a9b1b9e9-9d7c-4aa7-9d06-1b62ae6bf326"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1xoj4fkjFWbgZZGpDNuTyZsH1-eOzncVi/robotic arm data - s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jcQtFqegsF0",
        "outputId": "14a7c575-fde7-42e1-a7e1-e065a5ab462e"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_v2.pkl                  Samling_for_Zhen_Lizhuoxun_S.csv\n",
            "IMG_4598.MOV                 Samling_for_Zhen_l_s.csv\n",
            "IMG_4599.MOV                 Samling_for_Zhen_lyfg_2e_s.csv\n",
            "IMG_4600.MOV                 Samling_for_Zhen_lygf_e_s.csv\n",
            "IMG_4601.MOV                 Samling_for_Zhen_oyg_2e_s.csv\n",
            "IMG_4602.MOV                 Samling_for_Zhen_oyg_e_s1.csv\n",
            "Samling_for_Zhen_d_s2.csv    Samling_for_Zhen_w_s.csv\n",
            "Samling_for_Zhen_d_s.csv     Samling_for_Zhen_x_s.csv\n",
            "Samling_for_Zhen_g_S.csv     Samling_for_Zhen_yg_e_s.csv\n",
            "Samling_for_Zhen_lg_e_s.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xpKn73Rgx2k"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2xd8cDg2k8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from google.colab import files\r\n",
        "import os\r\n",
        "import pickle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu57KDD_g8Z0"
      },
      "source": [
        "file_name = \"data_v2.pkl\"\r\n",
        "open_file = open(file_name, \"rb\")\r\n",
        "Data = pickle.load(open_file)\r\n",
        "open_file.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CohWTdJ9hG0b",
        "outputId": "7ef21099-039e-422a-e124-b42e3c4c467e"
      },
      "source": [
        "Data.keys()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Zhen_d_s', 'Zhen_d_s2', 'Zhen_g_S', 'Zhen_l_s', 'Zhen_lg_e_s', 'Zhen_Lizhuoxun_S', 'Zhen_lyfg_2e_s', 'Zhen_lygf_e_s', 'Zhen_oyg_2e_s', 'Zhen_oyg_e_s1', 'Zhen_w_s', 'Zhen_x_s', 'Zhen_yg_e_s'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxIs1W3RENmA",
        "outputId": "80baa62d-e24d-4d4e-d36f-984598c71feb"
      },
      "source": [
        "count = 0\r\n",
        "for key in Data.keys():\r\n",
        "  _,a = Data[key]\r\n",
        "  count+= a.shape[0]\r\n",
        "  print(key,a.shape)\r\n",
        "print('Total Samples:',count)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zhen_d_s (189, 21, 5000, 1)\n",
            "Zhen_d_s2 (189, 21, 5000, 1)\n",
            "Zhen_g_S (231, 21, 5000, 1)\n",
            "Zhen_l_s (237, 21, 5000, 1)\n",
            "Zhen_lg_e_s (237, 21, 5000, 1)\n",
            "Zhen_Lizhuoxun_S (242, 21, 5000, 1)\n",
            "Zhen_lyfg_2e_s (242, 21, 5000, 1)\n",
            "Zhen_lygf_e_s (242, 21, 5000, 1)\n",
            "Zhen_oyg_2e_s (242, 21, 5000, 1)\n",
            "Zhen_oyg_e_s1 (242, 21, 5000, 1)\n",
            "Zhen_w_s (269, 21, 5000, 1)\n",
            "Zhen_x_s (269, 21, 5000, 1)\n",
            "Zhen_yg_e_s (269, 21, 5000, 1)\n",
            "Total Samples: 3100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUQjHN-zE4eY",
        "outputId": "d42da4a7-1207-46d2-8f8c-04ae6c45e71f"
      },
      "source": [
        "count/(5*13)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.69230769230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU8JCFOEFLf_"
      },
      "source": [
        "Lets take 45 samples from each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXL_ds0vFKyJ",
        "outputId": "5230de59-8821-43af-e76f-68d8fedf3075"
      },
      "source": [
        "#count = 0\r\n",
        "for key in Data.keys():\r\n",
        "  _,a = Data[key]\r\n",
        "  #count+= a.shape[0]\r\n",
        "  b = a.shape[0]\r\n",
        "  b = round(45*100/b)\r\n",
        "  print(key,b)\r\n",
        "#print('Total Samples:',count)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zhen_d_s 24\n",
            "Zhen_d_s2 24\n",
            "Zhen_g_S 19\n",
            "Zhen_l_s 19\n",
            "Zhen_lg_e_s 19\n",
            "Zhen_Lizhuoxun_S 19\n",
            "Zhen_lyfg_2e_s 19\n",
            "Zhen_lygf_e_s 19\n",
            "Zhen_oyg_2e_s 19\n",
            "Zhen_oyg_e_s1 19\n",
            "Zhen_w_s 17\n",
            "Zhen_x_s 17\n",
            "Zhen_yg_e_s 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naepyOndYxtt"
      },
      "source": [
        "## Defining some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqpFOAeX-5n"
      },
      "source": [
        "def restructure_time_data(time_stamp):\r\n",
        "  '''\r\n",
        "  The previous time stamps are arranged in a way that all the points of time are listed.\r\n",
        "  However, they can be restructered so that the dictionary consists of a list that has\r\n",
        "  the start and ending of the signal segment.\r\n",
        "  '''\r\n",
        "  start_end_time ={}\r\n",
        "  for key in time_stamp.keys():\r\n",
        "    temp1 = time_stamp[key]\r\n",
        "    time = [temp1.iloc[0],temp1.iloc[-1]]\r\n",
        "    start_end_time[key]= time\r\n",
        "  \r\n",
        "  return start_end_time"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6l-V-fOaSXt"
      },
      "source": [
        "def split_time_data(time_stamp,val_size):\r\n",
        "  '''\r\n",
        "  Splitting the time_data from start till we have only a specific\r\n",
        "  amount of signals left.\r\n",
        "  Input:\r\n",
        "    time_stamp - a dictionary containing the time data\r\n",
        "    val_size   - integer that specifies the amount of validation signals\r\n",
        "  '''\r\n",
        "  idx = len(time_stamp)- val_size\r\n",
        "  train_time = {}\r\n",
        "  val_time   = {}\r\n",
        "  for key in time_stamp.keys():\r\n",
        "    if key < idx:\r\n",
        "      train_time[key] = time_stamp[key]\r\n",
        "    else :\r\n",
        "      val_time[key]   = time_stamp[key]\r\n",
        "  return train_time, val_time\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnLqn-E7ufpd"
      },
      "source": [
        "# Preparing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOfoxyBwjkbC"
      },
      "source": [
        "name_class = {}\r\n",
        "count = 0\r\n",
        "for key in Data.keys():\r\n",
        "  name_class[key] = count\r\n",
        "  count += 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPYaTYoj4-B"
      },
      "source": [
        "`name_class` is going to be used to change the names of the subjects to integers. We will later use One-hot encoding to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE2lxHdKj1tQ",
        "outputId": "67c957eb-d3cf-47e7-b557-1e8cb0233741"
      },
      "source": [
        "for key in name_class:\r\n",
        "  print(key,':',name_class[key])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zhen_d_s : 0\n",
            "Zhen_d_s2 : 1\n",
            "Zhen_g_S : 2\n",
            "Zhen_l_s : 3\n",
            "Zhen_lg_e_s : 4\n",
            "Zhen_Lizhuoxun_S : 5\n",
            "Zhen_lyfg_2e_s : 6\n",
            "Zhen_lygf_e_s : 7\n",
            "Zhen_oyg_2e_s : 8\n",
            "Zhen_oyg_e_s1 : 9\n",
            "Zhen_w_s : 10\n",
            "Zhen_x_s : 11\n",
            "Zhen_yg_e_s : 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ozCrGBizmS"
      },
      "source": [
        "Main Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8_GKjB1Y4sO"
      },
      "source": [
        "time_dict = {}\r\n",
        "first_flag = True\r\n",
        "# Main Loop\r\n",
        "for class_key in Data.keys():\r\n",
        "  time_stamp,sig = Data[class_key]               # Unpacking the data of each class\r\n",
        "  time_stamp = restructure_time_data(time_stamp)  # restructuring the time data\r\n",
        "\r\n",
        "  # Split into train and validation set\r\n",
        "  val_size = 45 # as predetermined\r\n",
        "\r\n",
        "  train_time, val_time = split_time_data(time_stamp, val_size)  # split the time stamp\r\n",
        "  temp_train_sig = sig[:-val_size]                              # split the signal\r\n",
        "  temp_val_sig   = sig[-val_size:]                              # ...\r\n",
        "\r\n",
        "  temp_train_class = np.ones((temp_train_sig.shape[0],1))       # creating empty np array for class data\r\n",
        "  temp_val_class   = np.ones((val_size,1))\r\n",
        "\r\n",
        "  class_value = name_class[class_key]                           # getting the class value from the dictionary\r\n",
        "  temp_train_class.fill(class_value)                            # assigning class data\r\n",
        "  temp_val_class.fill(class_value)\r\n",
        "  # Saving the data\r\n",
        "  time_dict[class_key] = (train_time,val_time)                 # saving time data\r\n",
        "\r\n",
        "  if first_flag:                                                # for first time\r\n",
        "    train_sig   = temp_train_sig\r\n",
        "    val_sig     = temp_val_sig\r\n",
        "    train_class = temp_train_class\r\n",
        "    val_class   = temp_val_class\r\n",
        "    first_flag = False\r\n",
        "  else:\r\n",
        "    train_sig   = np.concatenate((train_sig,  temp_train_sig))\r\n",
        "    val_sig     = np.concatenate((val_sig,    temp_val_sig))\r\n",
        "    train_class = np.concatenate((train_class,temp_train_class))\r\n",
        "    val_class   = np.concatenate((val_class,  temp_val_class))\r\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGpT0Grssxtv",
        "outputId": "139e14c4-21c0-49e1-c953-0436f55291d0"
      },
      "source": [
        "print('The total data')\r\n",
        "print('Training Data shape:',train_sig.shape)\r\n",
        "print('Validation Data shape:',val_sig.shape)\r\n",
        "print('Training Class shape:',train_class.shape)\r\n",
        "print('Validation Class shape:',val_class.shape)\r\n",
        "temp = val_sig.shape[0]/(train_sig.shape[0] + val_sig.shape[0])\r\n",
        "print('Proportion of Validation Data:',round(temp*100,2),'%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total data\n",
            "Training Data shape: (2515, 21, 5000, 1)\n",
            "Validation Data shape: (585, 21, 5000, 1)\n",
            "Training Class shape: (2515, 1)\n",
            "Validation Class shape: (585, 1)\n",
            "Proportion of Validation Data: 18.87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev2kv-2GzYiD"
      },
      "source": [
        "## Shuffling the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQZCHr4RzwAR"
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBvT7qTDzb7B"
      },
      "source": [
        "train_idx = np.arange(0,train_sig.shape[0])\r\n",
        "val_idx = np.arange(0,val_sig.shape[0])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMbMR8S0SRi"
      },
      "source": [
        "np.random.shuffle(train_idx)\r\n",
        "np.random.shuffle(val_idx)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV3Nh4l20cBA",
        "outputId": "611cec1a-8d3b-4581-ea3a-de76553371f7"
      },
      "source": [
        "train_idx"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 617,  927,  942, ..., 1130, 1294,  860])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UyAoDJA0eVD"
      },
      "source": [
        "train_sig   = train_sig[train_idx,:,:,:]\r\n",
        "train_class = train_class[train_idx,:]\r\n",
        "val_sig     = val_sig[val_idx,:,:,:]\r\n",
        "val_class   = val_class[val_idx,:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5O68i8T00_Z",
        "outputId": "9ee6c707-5a9a-476f-c8c6-bd33c54aff5c"
      },
      "source": [
        "train_class[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu9pD2j4xfXy"
      },
      "source": [
        "# Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvU18ht9xeZl"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "# import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, MaxPool1d, Module, Softmax, BatchNorm1d, Dropout, MSELoss\r\n",
        "from torch.optim import Adam, SGD\r\n",
        "\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VkjvWDyHjS"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 32, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(32),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(32, 64, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(64),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(64, 64, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(64),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOfL2MEh4fwu",
        "outputId": "2b7b41ef-27ee-4eda-cd4c-26b3a46d9a16"
      },
      "source": [
        "net = Net(21)\r\n",
        "print(net)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv1d(21, 32, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=39872, out_features=13, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-prNma94Pqw",
        "outputId": "007869ac-5606-4f0a-ff74-fe10b478c78c"
      },
      "source": [
        "from torchsummary import summary\r\n",
        "summary(net.cuda(), (21,5000))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1             [-1, 32, 4998]           3,392\n",
            "       BatchNorm1d-2             [-1, 32, 4998]              64\n",
            "              ReLU-3             [-1, 32, 4998]               0\n",
            "         MaxPool1d-4             [-1, 32, 2499]               0\n",
            "            Conv1d-5             [-1, 64, 2497]          10,304\n",
            "       BatchNorm1d-6             [-1, 64, 2497]             128\n",
            "              ReLU-7             [-1, 64, 2497]               0\n",
            "         MaxPool1d-8             [-1, 64, 1248]               0\n",
            "            Conv1d-9             [-1, 64, 1246]          20,544\n",
            "      BatchNorm1d-10             [-1, 64, 1246]             128\n",
            "             ReLU-11             [-1, 64, 1246]               0\n",
            "        MaxPool1d-12              [-1, 64, 623]               0\n",
            "          Flatten-13                [-1, 39872]               0\n",
            "           Linear-14                   [-1, 13]         518,349\n",
            "================================================================\n",
            "Total params: 552,909\n",
            "Trainable params: 552,909\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 10.97\n",
            "Params size (MB): 2.11\n",
            "Estimated Total Size (MB): 13.48\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljRapXhv_IQk",
        "outputId": "b14d8a5c-b81c-4c65-ab3a-a80a94ffc4fd"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-S_5iW76Eq-"
      },
      "source": [
        "optimizer = Adam(net.parameters(),lr = 1e-3)\r\n",
        "#criterion = CrossEntropyLoss()\r\n",
        "criterion = MSELoss()\r\n",
        "if torch.cuda.is_available():\r\n",
        "  net = net.cuda()\r\n",
        "  criterion = criterion.cuda()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "-rYuClNWHjZw",
        "outputId": "d490d3f5-167e-4a54-8d66-09eba29a29f1"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\r\n",
        "a = enc.fit_transform(train_y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f5b34473990b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \"\"\"\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \"\"\"\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mX_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[1;32m     45\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    509\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    307\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                         'convert to a dense numpy array.')\n",
            "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "savfqV3Q6uSF"
      },
      "source": [
        "# converting training images into torch format\r\n",
        "train_x = train_sig.astype(float)\r\n",
        "train_x = train_x.reshape(train_sig.shape[0], 21,5000)\r\n",
        "train_x  = torch.from_numpy(train_x)\r\n",
        "\r\n",
        "# converting the target into torch format\r\n",
        "train_y = train_class.astype(int)\r\n",
        "#train_y = enc.fit_transform(train_y)\r\n",
        "train_y = torch.from_numpy(train_y)\r\n",
        "\r\n",
        "# shape of training data\r\n",
        "train_x.shape, train_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ_1hn3zCFBr"
      },
      "source": [
        "type(train_x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvrM2Jx7vSH"
      },
      "source": [
        "# converting training images into torch format\r\n",
        "val_x = val_sig.astype(float)\r\n",
        "val_x = val_sig.reshape(val_sig.shape[0], 21,5000)\r\n",
        "val_x  = torch.from_numpy(val_x)\r\n",
        "\r\n",
        "# converting the target into torch format\r\n",
        "val_y = val_class.astype(int)\r\n",
        "val_y = \r\n",
        "val_y = torch.from_numpy(val_y)\r\n",
        "\r\n",
        "# shape of training data\r\n",
        "val_x.shape, val_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrTTcAJdH8ZX"
      },
      "source": [
        "print(a[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0F-UmoT6fj_"
      },
      "source": [
        "def train(model,batch_size,epochs):\r\n",
        "    tr_loss = 0\r\n",
        "    for epoch in range(epochs):\r\n",
        "      for i in tqdm(range(0,len(train_y),batch_size)):\r\n",
        "        batch_X = train_x[i:i+batch_size].float()\r\n",
        "        batch_y = train_y[i:i+batch_size]\r\n",
        "\r\n",
        "        if torch.cuda.is_available():\r\n",
        "          batch_X = batch_X.cuda()\r\n",
        "          batch_y = batch_y.cuda()\r\n",
        "\r\n",
        "        model.zero_grad()\r\n",
        "        output_train = model(batch_X)\r\n",
        "        print(output_train.shape)\r\n",
        "        print(output_train)\r\n",
        "        print(batch_y.shape)\r\n",
        "        loss_train = criterion(output_train, batch_y)\r\n",
        "        train_losses.append(loss_train)\r\n",
        "        # computing the updated weights of all the model parameters\r\n",
        "        loss_train.backward()\r\n",
        "        optimizer.step()\r\n",
        "        tr_loss = loss_train.item()\r\n",
        "      with torch.no_grad():\r\n",
        "        for j in tqdm(range(0,len(val_y),batch_size)):\r\n",
        "          val_batch_X = val_x[i:i+batch_size].float()\r\n",
        "          val_batch_y = val_y[i:i+batch_size]\r\n",
        "\r\n",
        "          if torch.cuda.is_available():\r\n",
        "            val_batch_X = val_batch_X.cuda()\r\n",
        "            val_batch_y = val_batch_y.cuda()\r\n",
        "\r\n",
        "          output_val = model(val_batch_X)\r\n",
        "          loss_val = criterion(output_val, val_batch_y)\r\n",
        "          val_losses.append(loss_val)   \r\n",
        "      if (epoch+1)%10 == 0:\r\n",
        "        # printing the validation loss\r\n",
        "          print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)     \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqv3p8RGFS3R"
      },
      "source": [
        "val_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH99ECoQ8cEk"
      },
      "source": [
        "# defining the number of epochs\r\n",
        "n_epochs = 200\r\n",
        "batch_size = 32\r\n",
        "# empty list to store training losses\r\n",
        "train_losses = []\r\n",
        "# empty list to store validation losses\r\n",
        "val_losses = []\r\n",
        "# training the model\r\n",
        "train(net,batch_size,n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}