{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Robot - Data Processing 5",
      "provenance": [],
      "collapsed_sections": [
        "naepyOndYxtt"
      ],
      "authorship_tag": "ABX9TyPW+D9s5KM6grGWD5JQBMqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moajjem04/Pytorch_Practice/blob/main/Robot_Data_Processing_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8qKGEwzgixm"
      },
      "source": [
        "# Accessing Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXY6FMlJgedd",
        "outputId": "e03ca2cf-c0fe-49ba-ffc1-13bd2e9519b4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgKVXwzUgop4",
        "outputId": "ec46074f-0732-4696-8599-c04109c8937c"
      },
      "source": [
        "%cd '/content/drive/MyDrive/robot'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1xoj4fkjFWbgZZGpDNuTyZsH1-eOzncVi/robotic arm data - s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LOZbAmWtgqWE",
        "outputId": "90b291de-0149-4ead-97fd-87d2f2341fd0"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1xoj4fkjFWbgZZGpDNuTyZsH1-eOzncVi/robotic arm data - s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jcQtFqegsF0",
        "outputId": "48c61caa-5cf2-400a-d94b-eee7384e0875"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_v2.pkl   Samling_for_Zhen_d_s2.csv         Samling_for_Zhen_lygf_e_s.csv\n",
            "data_v3.pkl   Samling_for_Zhen_d_s.csv          Samling_for_Zhen_oyg_2e_s.csv\n",
            "IMG_4598.MOV  Samling_for_Zhen_g_S.csv          Samling_for_Zhen_oyg_e_s1.csv\n",
            "IMG_4599.MOV  Samling_for_Zhen_lg_e_s.csv       Samling_for_Zhen_w_s.csv\n",
            "IMG_4600.MOV  Samling_for_Zhen_Lizhuoxun_S.csv  Samling_for_Zhen_x_s.csv\n",
            "IMG_4601.MOV  Samling_for_Zhen_l_s.csv          Samling_for_Zhen_yg_e_s.csv\n",
            "IMG_4602.MOV  Samling_for_Zhen_lyfg_2e_s.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xpKn73Rgx2k"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2xd8cDg2k8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from google.colab import files\r\n",
        "import os\r\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu57KDD_g8Z0"
      },
      "source": [
        "file_name = \"data_v3.pkl\"\r\n",
        "open_file = open(file_name, \"rb\")\r\n",
        "Data = pickle.load(open_file)\r\n",
        "open_file.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CohWTdJ9hG0b",
        "outputId": "609d1a2a-763f-4b60-fbd0-520a7db14e91"
      },
      "source": [
        "Data.keys()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['name_class', 'train_sig', 'val_sig', 'train_class', 'val_class', 'time_dict'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU66FU9QM02u"
      },
      "source": [
        "name_class  = Data['name_class']\r\n",
        "train_sig   = Data['train_sig']\r\n",
        "val_sig     = Data['val_sig']\r\n",
        "train_class = Data['train_class']\r\n",
        "val_class   = Data['val_class']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCO7Kam3NH6-"
      },
      "source": [
        "%reset_selective -f Data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPe5fL6UN-Jf",
        "outputId": "97c1b089-7f62-4609-dfee-37861b287441"
      },
      "source": [
        "try:\r\n",
        "  Data.keys()\r\n",
        "except:\r\n",
        "  print('No Data')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGpT0Grssxtv",
        "outputId": "37dedaca-c682-49e0-c05d-a582e757259c"
      },
      "source": [
        "print('The total data')\r\n",
        "print('Training Data shape:',train_sig.shape)\r\n",
        "print('Validation Data shape:',val_sig.shape)\r\n",
        "print('Training Class shape:',train_class.shape)\r\n",
        "print('Validation Class shape:',val_class.shape)\r\n",
        "temp = val_sig.shape[0]/(train_sig.shape[0] + val_sig.shape[0])\r\n",
        "print('Proportion of Validation Data:',round(temp*100,2),'%')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total data\n",
            "Training Data shape: (2515, 21, 5000, 1)\n",
            "Validation Data shape: (585, 21, 5000, 1)\n",
            "Training Class shape: (2515, 1)\n",
            "Validation Class shape: (585, 1)\n",
            "Proportion of Validation Data: 18.87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev2kv-2GzYiD"
      },
      "source": [
        "## Shuffling the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQZCHr4RzwAR"
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBvT7qTDzb7B"
      },
      "source": [
        "train_idx = np.arange(0,train_sig.shape[0])\r\n",
        "val_idx = np.arange(0,val_sig.shape[0])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMbMR8S0SRi"
      },
      "source": [
        "np.random.shuffle(train_idx)\r\n",
        "np.random.shuffle(val_idx)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV3Nh4l20cBA",
        "outputId": "d984b661-e66b-4de4-d85d-ba97e8b50e4b"
      },
      "source": [
        "train_idx"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 617,  927,  942, ..., 1130, 1294,  860])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UyAoDJA0eVD"
      },
      "source": [
        "train_sig   = train_sig[train_idx,:,:,:]\r\n",
        "train_class = train_class[train_idx,:]\r\n",
        "val_sig     = val_sig[val_idx,:,:,:]\r\n",
        "val_class   = val_class[val_idx,:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFw5b2hjPRxQ",
        "outputId": "507ce591-1e84-4266-9a33-adfb0af45326"
      },
      "source": [
        "val_class = val_class.reshape(val_class.shape[0])\r\n",
        "print(val_class.shape)\r\n",
        "train_class = train_class.reshape(train_class.shape[0])\r\n",
        "print(train_class.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(585,)\n",
            "(2515,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5O68i8T00_Z",
        "outputId": "67a5b926-73aa-4948-abc7-7d81b8670bb9"
      },
      "source": [
        "train_class[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu9pD2j4xfXy"
      },
      "source": [
        "# Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvU18ht9xeZl"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "# import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv1d, MaxPool1d, Module, Softmax, BatchNorm1d, Dropout, MSELoss\r\n",
        "from torch.optim import Adam, SGD\r\n",
        "\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGYnbYDpp7UG"
      },
      "source": [
        "class Layer3_ConvNet(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2)\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY1LoPVOqE1l"
      },
      "source": [
        "class Layer4_ConvNet(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2)\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VkjvWDyHjS"
      },
      "source": [
        "class Layer5_ConvNet(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=2, stride=2)\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13EE-8j3sVfP"
      },
      "source": [
        "class Layer5a_ConvNet(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5)\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BisfLactAxn"
      },
      "source": [
        "class Layer5b_ConvNet(nn.Module):\r\n",
        "  def __init__(self,n_channels):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.cnn_layers = Sequential(\r\n",
        "        # Defining a 1D convolution layer\r\n",
        "        Conv1d(n_channels, 21*2, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21*2),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21*2, 21*4, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21*4),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21*4, 21*4, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21*4),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21*4, 21*2, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21*2),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5),\r\n",
        "        # Defining another 1D convolution layer\r\n",
        "        Conv1d(21*2, 21, kernel_size=5, padding=1),\r\n",
        "        BatchNorm1d(21),\r\n",
        "        ReLU(inplace=True),\r\n",
        "        MaxPool1d(kernel_size=5)\r\n",
        "    )\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(21,5000).view(-1,21,5000)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.linear_layers = Sequential(\r\n",
        "                Linear(self._to_linear, 13)\r\n",
        "            )\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = self.cnn_layers(x)\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = self.linear_layers(x)\r\n",
        "    return x"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOfL2MEh4fwu",
        "outputId": "d15174fb-ed46-4075-ecdb-9f8f96f9eb6f"
      },
      "source": [
        "net = Layer5b_ConvNet(21)\r\n",
        "print(net)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer5b_ConvNet(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv1d(21, 42, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv1d(42, 84, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (5): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv1d(84, 84, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (9): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv1d(84, 42, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (13): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv1d(42, 21, kernel_size=(5,), stride=(1,), padding=(1,))\n",
            "    (17): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=21, out_features=13, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-prNma94Pqw",
        "outputId": "b7970174-d3aa-4d60-d061-93105dae27bf"
      },
      "source": [
        "from torchsummary import summary\r\n",
        "summary(net.cuda(), (21,5000))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1             [-1, 42, 4998]           4,452\n",
            "       BatchNorm1d-2             [-1, 42, 4998]              84\n",
            "              ReLU-3             [-1, 42, 4998]               0\n",
            "         MaxPool1d-4              [-1, 42, 999]               0\n",
            "            Conv1d-5              [-1, 84, 997]          17,724\n",
            "       BatchNorm1d-6              [-1, 84, 997]             168\n",
            "              ReLU-7              [-1, 84, 997]               0\n",
            "         MaxPool1d-8              [-1, 84, 199]               0\n",
            "            Conv1d-9              [-1, 84, 197]          35,364\n",
            "      BatchNorm1d-10              [-1, 84, 197]             168\n",
            "             ReLU-11              [-1, 84, 197]               0\n",
            "        MaxPool1d-12               [-1, 84, 39]               0\n",
            "           Conv1d-13               [-1, 42, 37]          17,682\n",
            "      BatchNorm1d-14               [-1, 42, 37]              84\n",
            "             ReLU-15               [-1, 42, 37]               0\n",
            "        MaxPool1d-16                [-1, 42, 7]               0\n",
            "           Conv1d-17                [-1, 21, 5]           4,431\n",
            "      BatchNorm1d-18                [-1, 21, 5]              42\n",
            "             ReLU-19                [-1, 21, 5]               0\n",
            "        MaxPool1d-20                [-1, 21, 1]               0\n",
            "          Flatten-21                   [-1, 21]               0\n",
            "           Linear-22                   [-1, 13]             286\n",
            "================================================================\n",
            "Total params: 80,485\n",
            "Trainable params: 80,485\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 7.61\n",
            "Params size (MB): 0.31\n",
            "Estimated Total Size (MB): 8.32\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgueD-9XqKFc"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljRapXhv_IQk",
        "outputId": "a94522aa-5d92-4b89-b452-5a303a36a2d9"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSaZAGG7qP61"
      },
      "source": [
        "## Convert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "savfqV3Q6uSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44efb33-64a9-4036-e55d-262a2ac005ad"
      },
      "source": [
        "# converting training images into torch format\r\n",
        "train_x = train_sig.astype(float)\r\n",
        "train_x = train_x.reshape(train_sig.shape[0], 21,5000)\r\n",
        "train_x  = torch.from_numpy(train_x)\r\n",
        "\r\n",
        "# converting the target into torch format\r\n",
        "train_y = train_class.astype(int)\r\n",
        "#train_y = enc.fit_transform(train_y)\r\n",
        "train_y = torch.from_numpy(train_y)\r\n",
        "\r\n",
        "# shape of training data\r\n",
        "train_x.shape, train_y.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2515, 21, 5000]), torch.Size([2515]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ_1hn3zCFBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712fda30-8496-431c-c481-b1f61efb6732"
      },
      "source": [
        "type(train_x[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvrM2Jx7vSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4169cb-5b5f-428a-a364-27c53f0ad802"
      },
      "source": [
        "# converting training images into torch format\r\n",
        "val_x = val_sig.astype(float)\r\n",
        "val_x = val_sig.reshape(val_sig.shape[0], 21,5000)\r\n",
        "val_x  = torch.from_numpy(val_x)\r\n",
        "\r\n",
        "# converting the target into torch format\r\n",
        "val_y = val_class.astype(int)\r\n",
        "#val_y = \r\n",
        "val_y = torch.from_numpy(val_y)\r\n",
        "\r\n",
        "# shape of training data\r\n",
        "val_x.shape, val_y.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([585, 21, 5000]), torch.Size([585]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q42KPdcxqSt-"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0F-UmoT6fj_"
      },
      "source": [
        "def train(model,batch_size,epochs,stop_count):\r\n",
        "    tag = 0;\r\n",
        "    stop_flag = False\r\n",
        "    count = 0\r\n",
        "    for epoch in range(epochs):\r\n",
        "      tr_loss = []\r\n",
        "      val_loss = []\r\n",
        "      for i in tqdm(range(0,len(train_y),batch_size)):\r\n",
        "        batch_X = train_x[i:i+batch_size].float()\r\n",
        "        batch_y = train_y[i:i+batch_size]\r\n",
        "\r\n",
        "        if torch.cuda.is_available():\r\n",
        "          batch_X = batch_X.cuda()\r\n",
        "          batch_y = batch_y.cuda()\r\n",
        "\r\n",
        "        model.zero_grad()\r\n",
        "        output_train = model(batch_X)\r\n",
        "        # print(output_train.shape)\r\n",
        "        # print(output_train)\r\n",
        "        # print(batch_y.shape)\r\n",
        "        loss_train = criterion(output_train, batch_y)\r\n",
        "        tr_loss.append(loss_train.item())\r\n",
        "\r\n",
        "        # computing the updated weights of all the model parameters\r\n",
        "        loss_train.backward()\r\n",
        "        optimizer.step()\r\n",
        "        #tr_loss = loss_train.item()\r\n",
        "      train_losses.append(np.mean(tr_loss))\r\n",
        "      with torch.no_grad():\r\n",
        "        for j in tqdm(range(0,len(val_y),batch_size)):\r\n",
        "          val_batch_X = val_x[j:j+batch_size].float()\r\n",
        "          val_batch_y = val_y[j:j+batch_size]\r\n",
        "          # print(val_batch_X.shape)\r\n",
        "          # print(batch_X.shape)\r\n",
        "\r\n",
        "          if torch.cuda.is_available():\r\n",
        "            val_batch_X = val_batch_X.cuda()\r\n",
        "            val_batch_y = val_batch_y.cuda()\r\n",
        "\r\n",
        "          output_val = model(val_batch_X)\r\n",
        "          loss_val = criterion(output_val, val_batch_y)\r\n",
        "          val_loss.append(loss_val.item())   \r\n",
        "        val_losses.append(np.mean(val_loss))\r\n",
        "      if not stop_flag:\r\n",
        "        tag = np.mean(val_loss)\r\n",
        "        stop_flag = True\r\n",
        "      else:\r\n",
        "        if tag< np.mean(val_loss):\r\n",
        "          count += 1\r\n",
        "        else:\r\n",
        "          tag = np.mean(val_loss)\r\n",
        "          count = 0\r\n",
        "      if count >= stop_count:\r\n",
        "        print('\\nEarly Stopping at epoch #',epoch,'with minimum val loss',tag,'and final val loss',np.mean(val_loss))\r\n",
        "        break;     \r\n",
        "      if (epoch+1)%10 == 0:\r\n",
        "        # printing the validation loss\r\n",
        "          print('Epoch : ',epoch+1, '\\t', 'val loss :', np.mean(val_loss))  \r\n",
        "          print('Epoch : ',epoch+1, '\\t', 'train loss :', np.mean(tr_loss))     \r\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-S_5iW76Eq-"
      },
      "source": [
        "net = Layer5b_ConvNet(21)\r\n",
        "optimizer = Adam(net.parameters(),lr = 3e-3)\r\n",
        "criterion = CrossEntropyLoss()\r\n",
        "#criterion = MSELoss()\r\n",
        "if torch.cuda.is_available():\r\n",
        "  net = net.cuda()\r\n",
        "  criterion = criterion.cuda()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH99ECoQ8cEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c948602d-c56c-41f4-cc48-6eaec402b7bf"
      },
      "source": [
        "# %%capture\r\n",
        "# defining the number of epochs\r\n",
        "n_epochs = 200\r\n",
        "batch_size = 32*4\r\n",
        "stop_count = 6\r\n",
        "# empty list to store training losses\r\n",
        "train_losses = []\r\n",
        "# empty list to store validation losses\r\n",
        "val_losses = []\r\n",
        "# training the model\r\n",
        "train(net,batch_size,n_epochs,stop_count)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:01<00:00, 19.42it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.41it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.74it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.31it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.44it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.45it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.75it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.56it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.84it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.28it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.08it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.02it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 25.70it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 21.17it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 26.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Early Stopping at epoch # 7 with minimum val loss 2.3312519073486326 and final val loss 2.503953552246094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAeekADNqU9l"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0NlopKz5aih6",
        "outputId": "49c9ffd9-b694-471f-99b5-b168c9476f08"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(train_losses,label = 'Train')\r\n",
        "plt.plot(val_losses, label = 'Val')\r\n",
        "plt.legend()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f45454a5cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9bnv8c+TmYyQgTAkIUyCyCAQJqkWa61zqa1acaTtqVXbim09Xo/3tLU97T29PZ5eq7VaTm2doVa0WluttWpFUSSMCggECEkYkhBCQoDMv/vH2pAEEhIgydp75/t+vfaLnb3X3vsJL/jmybPW+i1zziEiIqEvwu8CRESkeyjQRUTChAJdRCRMKNBFRMKEAl1EJExE+fXB6enpLjc316+PFxEJSStXrtzrnMto7znfAj03N5f8/Hy/Pl5EJCSZ2Y6OntPIRUQkTCjQRUTChAJdRCRM+DZDb09DQwMlJSXU1tb6XUqPi4uLIysri+joaL9LEZEwEVSBXlJSQlJSErm5uZiZ3+X0GOccFRUVlJSUMHz4cL/LEZEwEVQjl9raWtLS0sI6zAHMjLS0tD7xm4iI9J6gCnQg7MP8iL7yfYpI7wmqkYtIWHIOdiyD4uXQPwfSRkHaSIhN8rsyCTMK9FYqKiq44IILANizZw+RkZFkZHgnZH344YfExMR0+Nr8/HyefPJJHnzwwV6pVULAgT2w5llY/TTs23r880mDW8I9bbR3P320F/qR2lkuJ0+B3kpaWhpr1qwB4L777iMxMZG77rrr6PONjY1ERbX/V5aXl0deXl6v1ClBrKkBNv8NVj8FW/4OrglyzoHz7oLRF0HNHqgogL1boGKrd3/DS3C4suU9IqJgQG4g5Ee2BH3aKEjMBI3rpAMK9E7Mnz+fuLg4Vq9ezezZs7n22mtZsGABtbW19OvXj9///veMGTOGt99+m/vvv59XXnmF++67j6KiIrZt20ZRURF33nknd9xxh9/fivSk8s1eiK9dDAfLvOCdfQecfQOkj2rZLiENMs86/vWH9rUK+oKW29Y3oamuZbuYpOND/sjXGuH0eUEb6D/683o27Kru1vccNySZH17Rzn+mTpSUlLBs2TIiIyOprq5m6dKlREVF8cYbb3DvvfeyZMmS417zySef8NZbb3HgwAHGjBnDbbfdpmPOw01dDax/0Qvy4uVgkXDGxTDlRhh1IUSexH+v+FSInw7Z09s+3twM1SVtO/qKLVDyIXy8BGh1CcnEQYGQDwT8kTHOgGEa4fQRQRvoweTqq68mMjISgKqqKm6++Wa2bNmCmdHQ0NDuay677DJiY2OJjY1l4MCBlJaWkpWV1ZtlS09wDoo/hNVPwscvQsNBLzgv/DFMvBaSMrv38yIivJl6/xwYdUHb5xpqYd+2th19RQFs/DMcqmj1HkdGOKPa3tJHa4QTZoI20E+lk+4pCQkJR+9///vf5/zzz+fFF1+ksLCQOXPmtPua2NjYo/cjIyNpbGzs6TKlJ9WUw9pF3g7OvZsgOgHOutLrxrNn+BOK0XGQOc67HevQvrYdfUUB7C2AbW9DY6vzH2IS2+6UTRvljYhSR0Jccq99K9I9gjbQg1VVVRVDhw4F4PHHH/e3GOlZTY1Q8IY3Utn8GjQ3QtZ0+PxDXpgH88w6PtW7ZU9r+3hzM1TvDIT81pa5fcmK40c48WmQkgUp2d6tf3bg6yxIyYGEdHX3QUaBfpLuvvtubr75Zn7yk59w2WWX+V2O9ISKrV4nvnYRHNgNCRkw8zaYfCNkjPG7utMTEeEFc/9sGPmZts811EJlYUtHv78I9hd7fx/b3ob6mrbbR8W1CvhAyKdktQR/8lCIikV6jznnOt+qB+Tl5bljL3CxceNGzjzzTF/q8UNf+36DWv0h7/DB1U/DjnfBIrwdm1Nu9HZ09vWdis5B7X6oKvFCvqoEqorafl2z55gXmTejbx3yR0L/yGNx/dXlnyQzW+mca/cYaXXo0nc5B7tWwaqnvHFDXTWkjoALfgCTroPkwX5XGDzMoN8A7zZoQvvbNNZ545z2Qn/PR7Dp1bbze/Bm+CnZbUP+yIgnJcs7+epkjhbq4/Q3JX3PwQpY9wevGy9bD1H94KwvwOQbYNhsdYynKirW+4GYOqL9552Dg3uP7+yrir3brlVtj84B71DQ5CGtZvmtQz/wWGxiz39vIUKBLn1DcxNsfcvbwfnJX6C5AYZOhcv/H4z/EsSl+F1h+DODxAzvNnRq+9vUH4SqnS2h3zr4iz+A9bu8ndOtxfX3Qn5AbqvbcO/PlGyI6njJjnCjQJfwVlkIq5/x1lSpLoF+qTD961433t4Zm+KvmATIOMO7tae5yVsjp3VnX1Xi7cAt3wSbX297Zq1FQHKWd3LVgFxIHd429PsNCKvfyBToEn4aar2Ta1Y/CdvfAcw7Keein8CYS3XkRSiLiISUod6NGcc/39zs7ZytLPRu+7a33N/8N29ZhtZik1vCvnVnH6LdvQJdwsfutd4Ozo+eg9oq7+zK8/83nH2dN2+V8BcR4c3ck4fAsHOOf77+IFTuCIR8q7APk+6+00A3s2zgSSAT76yDhc65Xx6zzRzgJWB74KEXnHM/7t5Se97555/PPffcw0UXXXT0sQceeIBNmzbxyCOPHLf9nDlzuP/++7XKop8OV8K6P3qz8T3rIDIWxn3eG6nknuf9Bxc5Iiah47NrW3f3rTv7LnX3w9vO8H3q7rvSoTcC33POrTKzJGClmf3dObfhmO2WOucu7/4Se8+8efNYvHhxm0BfvHgxP//5z32sStpoavCCu2g57HjPW6K2qQ4GT4JL74cJV3mdk8jJ6qy7r6uB/TvaBn1XuvvU4cfvsO2h7r7TQHfO7QZ2B+4fMLONwFDg2EAPeVdddRX//u//Tn19PTExMRQWFrJr1y4WLVrEd7/7XQ4fPsxVV13Fj370I79L7Ttqq6B4hXeEQ9EHsHMlNBzynuufA1Nv9s7gHDzR3zol/MUmejvS29uZ3tzsnVV8bNhXFsKm147v7md9Cy76abeXeFIzdDPLBSYDy9t5epaZrQV2AXc559a38/pbgFsAcnJyTvxhr97jnYzQnQZNgEt+1uHTqampTJ8+nVdffZW5c+eyePFirrnmGu69915SU1NpamriggsuYN26dUycqADpds55RysUL/fCu+gDKNsAOO945EETYMpN3mJYOTO9TkokGEREtOyszZ19/PPHdveDeiY/uhzoZpYILAHudM4du1D5KmCYc67GzC4F/gSMPvY9nHMLgYXgnfp/ylX3oCNjlyOB/thjj/Hcc8+xcOFCGhsb2b17Nxs2bFCgd4emRij9yBufHOnAD+z2notJ8haWGjcXcmbA0DydQCKh60TdfTfqUqCbWTRemD/jnHvh2OdbB7xz7q9m9mszS3fO7T3lyk7QSfekuXPn8p3vfIdVq1Zx6NAhUlNTuf/++1mxYgUDBgxg/vz51NbWdv5Gcrzaam9VvyMdeEm+t544eDuRhs32Ou/sGd4//IhIf+sVCTFdOcrFgMeAjc65X3SwzSCg1DnnzGw6EAFUtLdtsEtMTOT888/nq1/9KvPmzaO6upqEhARSUlIoLS3l1Vdf7XANdDlGVUnL6KT4AyhdD67Z22GUOR4mX98yPtFhhSKnrSsd+mzgRuAjM1sTeOxeIAfAOfcocBVwm5k1AoeBa51fyzh2g3nz5nHllVeyePFixo4dy+TJkxk7dizZ2dnMnt3OfEy8M/hK17eEd9Fy78xM8C4GkT0NzrvbG59kTQvutcRFQpSWz/VRSH+/dTWwM7+lAy/Jh/oD3nNJQ7yu++j4ZLxWzBPpJlo+V05f9a6245M9H4NrAsybd0/6MmTP9DrwlOygO4NOpC9QoMvxmpugbGPLkSdFy73V7wCi472V8s79Xsv4RCsVigSFoAt05xzWB7q7oNjF4Jy3/vTezd51JSu2QOkG70iUusCBS4mDvOCedbs3Phk0QVfvEQlSQRXocXFxVFRUkJaWFtah7pyjoqKCuLi43vnAxjpvbYqKLYHwDlwJfu8W77JiR0TGQvpob33wnFlekPcfpvGJSIgIqkDPysqipKSE8vJyv0vpcXFxcWRldeOhes5BTVlLUB/puPdu8c5Qc80t2yYNhrRRMP6LkH4GpI2G9FHe7FvHfouErKAK9OjoaIYPH+53GcGtoRb2bW0V2AVe111R0DImAe+yammjYMjZMOFqr/NOH+09pkMGRcJSUAV6lxQth/ce8HbExSZ7fx53O/J4f2+bUDtkzjnvqix7N7eE9tFuuwhvFeOA5Cyvu5745ZbATj8Dkodq6ViRPibEkg6or/EuO1X6sbcSX201bQKuPTGJHYR/O4/FJns/CFpv01NXuKk/1NJttx6RVBR43+cR0QmQNtI7ouTs6wKhHQjvmISeqU1EQk7oBfqoC7zbEc3N3gkttdWBgD/mVnfk8f0tj9WUet3vka9d04k/M6rfCcK/vd8Qjtnm8L6WoN67pWVEUlXc6kPMm2Gnj4KcG1qF9mhvVUHtmBSRToReoB8rIqIlPMk++dc7512Wqq6DHwjt/YA4XOktgXnksab6rn9eTFIgtGdB+k0toZ02EqL7nXz9IiIBoR/op8vMW9oyNvHU19duqG0n+Fvdj00O7JQ8AxIz1W2LSI9QoHeH6DjvlpTpdyUi0ofpMAgRkTChQBcRCRMKdBGRMKFAFxEJEwp0EZEwoUAXEQkTCnQRkTChQBcRCRMKdBGRMKFAFxEJEwp0EZEwoUAXEQkTCnQRkTChQBcRCRMKdBGRMKFAFxEJEwp0EZEwoUAXEQkTCnQRkTChQBcRCRMKdBGRMKFAFxEJEwp0EZEwoUAXEQkTCnQRkTDRaaCbWbaZvWVmG8xsvZktaGcbM7MHzazAzNaZ2ZSeKVdERDoS1YVtGoHvOedWmVkSsNLM/u6c29Bqm0uA0YHbDOCRwJ8iItJLOu3QnXO7nXOrAvcPABuBocdsNhd40nk+APqb2eBur1ZERDp0UjN0M8sFJgPLj3lqKFDc6usSjg99zOwWM8s3s/zy8vKTqzSgqdnxj42lp/RaEZFw1uVAN7NEYAlwp3Ou+lQ+zDm30DmX55zLy8jIOJW34A8rivnaE/ksWVlySq8XEQlXXQp0M4vGC/NnnHMvtLPJTiC71ddZgce63TV5Wcwckcq9L37ExzureuIjRERCUleOcjHgMWCjc+4XHWz2MnBT4GiXmUCVc253N9Z5VFRkBA9fN4W0hBi+8dRK9h2s74mPEREJOV3p0GcDNwKfMbM1gdulZnarmd0a2OavwDagAPgf4PaeKdeTlhjLozdOpbymjm89u4rGpuae/DgRkZDQ6WGLzrl3AetkGwd8s7uK6oqJWf35yRfGc/fz6/j53zZx76Vn9ubHi4gEna4chx60rsnL5qOSKha+s40JQ1O4YtIQv0sSEfFNyJ/6//3Lx5E3bAB3P7+OT/ac0sE3IiJhIeQDPSYqgl9fP4WkuChueXIlVYca/C5JRMQXIR/oAAOT43jkhinsrjrMgj+spqnZ+V2SiEivC4tAB5g6LJUfXnEWb28q54E3NvtdjohIrwubQAe4fkYO1+Rl8dCbBfxt/R6/yxER6VVhFehmxo/njmdSVgrfe24tBWU1fpckItJrwirQAeKiI3nkhqnERkVwy1P5HKjVTlIR6RvCLtABhvTvx8PXT2FHxSG+99xamrWTVET6gLAMdICZI9K499IzeX1DKb9+u8DvckREelzYBjrAV2fnMvfsIfz33zfz1qYyv8sREelRYR3oZsbPvjiRsYOSWbBoNYV7D/pdkohIjwnrQAfoFxPJwhunEhFh3Pr0Sg7VN/pdkohIjwj7QAfITo3nwWsns7n0AHc/vw5vcUgRkfDSJwId4LwzMrjrojG8sm43v1263e9yRES6XZ8JdIDbPj2SSycM4j9f3ch7BXv9LkdEpFv1qUA3M35+1SRGZiTyrWdXUVJ5yO+SRES6TZ8KdIDE2Ch+c+NUGpsctz69ktqGJr9LEhHpFn0u0AFGZCTywLVn8/HOau598SPtJBWRsNAnAx3ggjMzufOzo3lh1U6efH+H3+WIiJy2PhvoAHd8ZjSfPXMg//HKBj7cvs/vckRETkufDvSICOMXXz6b7NR4bn9mFXuqav0uSUTklPXpQAdIjotm4Y1TOVzfyG3PrKSuUTtJRSQ09flABxidmcT9V09iddF+7nt5g9/liIicEgV6wCUTBnPbnJEs+rCIxR8W+V2OiMhJU6C3ctfnxnDu6HR+8NJ6VhdV+l2OiMhJUaC3EhlhPDRvMpkpsdz29CrKD9T5XZKISJcp0I/RPz6G39yQx/7D9XzzmVU0NDX7XZKISJco0Nsxbkgy//dLE/mwcB8//ctGv8sREemSKL8LCFZzzx7K2uIqfvfediZlp3Dl5Cy/SxIROSF16Cfwb5eOZeaIVO5Z8hEf76zyuxwRkRNSoJ9AdGQEv7puCqkJMXzjqZXsO1jvd0kiIh1SoHciPTGWR2+YSnlNHXcsWk2jdpKKSJBSoHfBpOz+/GTueN4t2Mt/vb7J73JERNqlQO+ia6Zlc8PMHH7zz238Zd1uv8sRETmOAv0k/ODys5g6bAD/+vxaNu054Hc5IiJtKNBPQkxUBL++fgoJsVF846l8qg43+F2SiMhRCvSTlJkcxyPXT6Gk8jB3Ll5Nc7MuXyciwaHTQDez35lZmZl93MHzc8ysyszWBG4/6P4yg0tebio//PxZvLWpnAf+scXvckREgK6dKfo48CvgyRNss9Q5d3m3VBQibpiRw7ri/Tz4jy1MGJrCheMy/S5JRPq4Tjt059w7gC64eQwz4z++MJ6JWSl85w9r2Fpe43dJItLHddcMfZaZrTWzV83srI42MrNbzCzfzPLLy8u76aP9ExcdyaM3TCU2KoJvPLWSmrpGv0sSkT6sOwJ9FTDMOTcJeAj4U0cbOucWOufynHN5GRkZ3fDR/hvSvx+/um4K2/ce5K7n1uKcdpKKiD9OO9Cdc9XOuZrA/b8C0WaWftqVhZBZI9P4t0vG8tr6Pfz67a1+lyMifdRpB7qZDTIzC9yfHnjPitN931DztU8NZ+7ZQ7j/9U28vanM73JEpA/qymGLi4D3gTFmVmJmXzOzW83s1sAmVwEfm9la4EHgWtcH5w5mxs++OJGxg5JZsHgNRRWH/C5JRPoY8yt78/LyXH5+vi+f3ZOKKg5xxa/eZXBKHC/cfg7xMbqGiIh0HzNb6ZzLa+85nSnazXLS4nlw3mQ2lR7gniUfaSepiPQaBXoP+PQZGdz1uTG8vHYXj7273e9yRKSPUKD3kNvnjOSS8YP4z1c/4Z+bQ/+YexEJfgr0HmJm/NfVkxiVkchXfv8hv3h9Ew262pGI9CAFeg9KjI3i+dtmceXkLB58s4CrH32fwr0H/S5LRMKUAr2HJcVF89/XTOJX101mW3kNlz64lOfyi7WzVES6nQK9l1w+cQiv3XkeE4amcPfz6/jms6vYf6je77JEJIwo0HvRkP79ePbrM/lfF4/l9fWlXPzAUpYV7PW7LBEJEwr0XhYZYdw2ZyQv3j6b+NhIrn9sOf/5143UNTb5XZqIhDgFuk8mZKXwyrc/xXXTc/jNO9u48uFlFJTpwtMicuoU6D6Kj4nip1dO4H9uymNPdS2XPfguT71fqB2mInJKFOhB4MJxmbx257nMGJHG919az9eeyGdvTZ3fZYlIiFGgB4mBSXE8Pn8aP7xiHO8W7OXiB97hLS3DKyInQYEeRCIijK/MHs7L35pNemIsX/n9Cn740sfUNmiHqYh0ToEehMYOSuZP35zNV2cP54n3d3DFQ++yYVe132WJSJBToAepuOhIfnDFOJ746nT2H27gCw+/x2+XbqO5WTtMRaR9CvQg9+kzMnhtwbl8ekwGP/nLRm763YeUVtf6XZaIBCEFeghIS4xl4Y1T+T9XTmDljkoueuAdXvt4j99liUiQUaCHCDPjuhk5vHLHp8geEM+tT6/kniXrOFjX6HdpIhIkFOghZmRGIktuO4fb54zkD/nFXPbgUtYW7/e7LBEJAgr0EBQTFcHdF49l0ddnUt/YzJceWcav3txCk3aYivRpCvQQNnNEGq8uOI+Lxw/i/tc3M2/hB5RUHvK7LBHxiQI9xKXER/PQvMn84ppJbNhdzSW/XMpLa3b6XZaI+ECBHgbMjC9OyeLVBedyRmYSCxav4c7Fq6mubfC7NBHpRQr0MJKdGs8fbpnJdz57Bn9et5tLHljKisJ9fpclIr1EgR5moiIjWPDZ0fzx1llERhhf/s37/Pfrm2hoava7NBHpYQr0MDUlZwB/XXAuX5ySxUNvFnDVo++zfe9Bv8sSkR6kQA9jibFR3H/1JB6+bgrby2u47MGlPLeiWBfQEAlTCvQ+4LKJg3ntzvOYmJXC3UvWcfszq6g8WO93WSLSzRTofcSQ/v149l9m8m+XjOWNjaVc/Mt3eK9gr99liUg3UqD3IRERxjc+PZIXb59NQmwU1/92OT/9ywbqGnUBDZFwoEDvg8YPTeEv3z6X62fk8D9Lt/OFh5expfSA32WJyGlSoPdR/WIi+emVE/jtTXmUVtdy+UPv8tT7hdphKhLCFOh93GfHZfLanecyc0Qa339pPfN/v4I1Wr1RJCQp0IWBSXE8/pVp3HfFOFbuqOQLD7/H3Iff40+rd1LfqBOSREKF+fUrdl5ensvPz/fls6VjNXWNLFlZwhPvF7Kt/CDpibFcNyOHG2bkMDA5zu/yRPo8M1vpnMtr9zkFurSnudnxbsFeHl9WyFubyog049IJg5k/O5fJ2f0xM79LFOmTThToUV148e+Ay4Ey59z4dp434JfApcAhYL5zbtXplSx+i4gwzjsjg/POyKBw70GefH8Hf8wv5uW1u5iYlcLNs3K5fNJgYqMi/S5VRAI67dDN7DygBniyg0C/FPg2XqDPAH7pnJvR2QerQw89B+saeWH1Tp5YVkhBWQ3piTHMm57D9TOGMShF4xiR3nDaIxczywVe6SDQfwO87ZxbFPh6EzDHObf7RO+pQA9dzjneK6jg8WXb+ccn3jjm4vGD+MrsXKbkDNA4RqQHndbIpQuGAsWtvi4JPHZcoJvZLcAtADk5Od3w0eIHM+NTo9P51Oh0iioO8dQHhSxeUcwr63YzfmgyN8/K5YpJQ4iL1jhGpDf16mGLzrmFzrk851xeRkZGb3609JCctHj+92XjWH7vBfz0yvHUNzbzr8+v45yfvcl//e0Tdlcd9rtEkT6jOzr0nUB2q6+zAo9JHxIfE8X1M4Zx3fQc3t9awePLCnnk7a08+s9tXHzWIG4+J5dpuRrHiPSk7gj0l4FvmdlivJ2iVZ3NzyV8mRnnjErnnFHpFO87xNMf7GDximL+8tFuxg1OZv45uXz+bI1jRHpCV45yWQTMAdKBUuCHQDSAc+7RwGGLvwIuxjts8SvOuU73dmqnaN9xuL6JP63xjo75ZM8BBsRHc+30HG6YOYyh/fv5XZ5ISNGJRRIUnHMs376Px98r5PUNewD43LhBzJ+dy4zhqRrHiHRBTx/lItIlZsbMEWnMHJFGSeUhnv6giMUrinht/R7GDkpi/jm5zD17KP1iNI4RORXq0MVXtQ1NvLRmJ48v28HG3dWk9Ivm2mnZ3DBzGNmp8X6XJxJ0NHKRoOecY0VhJY8v287f1pfinOOzZ2Yyf3Yus0akaRwjEqCRiwQ9M2P68FSmD09l1/7DPLN8B4s+LOb1DaWMyUzipnOGceXkocTH6J+sSEfUoUvQqm1o4s9rd/H4skLW76omOS6KL0/L5qZZuRrHSJ+lkYuENOccK3dU8viyQl79eA/NznHB2Ezmn5PL7FEax0jfopGLhDQzIy83lbzcVPZU1fLM8h08u7yINzaWkpYQQ17uAKYFnj9rSDLRkboQl/RN6tAlJNU2NPHax3tYumUv+Tv2saPiEABx0RFMzh7AtNwB5OWmMjmnP0lx0T5XK9J9NHKRsFdWXUv+jko+3L6P/B372LCrmmYHEQZnDk4OdPBeJ5+pS+lJCFOgS59TU9fI6qJKVhRWkl+4j9VF+znc0ARAdmo/pg1LZdrwVKblDmBkRqLm8BIyNEOXPicxNopzR2dw7mhvmeaGpmY27KpmReE+8gsreWdLOS+s9hYFHRAfzdRhqUfHNOOHJuvSehKSFOjSJ0RHRjApuz+TsvvzL+d6R84UVhwKBLwX8m9sLAUgNsrb9kjAT8kZQEo/zeEl+GnkIhKwt6aO/MCIZsWOStbvrKKx2WEGYzKT2szhh2iVSPGJZugip+BQfSNriveTX1jJisJ9rNpRycF6bw4/tH8/8gId/LTcAZwxMImICM3hpedphi5yCuJjojhnZDrnjEwHoLGpmU/2HDjawb+/tYKX1uwCIDkuiqnDjgR8KhOzUnQRD+l16tBFTpFzjuJ9h705/I59rCispKCsBoCYyAgmZKV4I5ph3qimf3yMzxVLONDIRaSX7DtYz8odgTl84T4+2llFQ5P3f2xkRgKjByYxcmACowYmMjIjkREZiSTG6hdl6TqNXER6SWpCDBeOy+TCcZmAd0br2uL95O+oZE3xfjaXHeDvG0tpam5ppAYlxwUCPoGRgaAfmZFIZnKsjo+Xk6JAF+lBcdGRzBiRxowRaUcfq29spmjfQQrKDrK1vCZwO8iSVTupqWs8ul1ibJQX8hmJgaD3Ovuc1ARiorRejRxPgS7Sy2KiIhg1MIlRA5PaPO6co+xAHVvLvJAvKPOC/v1tFUdPggKIjDCGpcYzIiPRG98cDfxEHS/fxynQRYKEmZGZHEdmchznjEpv81xNXSPbyw9SUH6Ara06+39uLjs6owdIT4w92sm37uyHpPTTYZV9gAJdJAQkxkYxISuFCVkpbR5vbGqmuPLw0a7+SGf/57W7qK5tGd/0i45kxJHxTaCzH5mRyPD0BB1eGUYU6CIhLCoyguHpCQxPT+CzZB593DlHxcF6tpbVUFBec7SrX1VUyctrdx3dzgyyB8S3mdUf6e5TE3SYZahRoIuEITMjPTGW9MTYNjtkAQ7XN7Ftrzefb+nsD7JsawV1jc1Ht5ItaRMAAAcNSURBVBsQH82IjERGpHtH34xIT2BERiLD0uJ1EZEgpUAX6WP6xURy1pAUzhrSdnzT1OzYtf9woKP3Qn5beQ1vbSrnjytLjm4XFWHkHNkpm5FwdJQzQl297xToIgJ4R89kp8aTnRrP+WMGtnmu6nAD28pr2FZ+0Ovuy7w/39lcTn2TuvpgoUAXkU6l9Itmcs4AJucMaPN4U7OjpPIQ28oPHh3dqKv3jwJdRE5ZZIQxLC2BYWkJnD+2+7r6kQMTyUlVV3+yFOgi0iO6u6v3OvoEdfUnoEAXkV7VWVe/fa939M3JdPW5aQkMSoljUHIc6YkxRPXRzl6BLiJBI6VfNGdn9+fs7P5tHu9qVw8QYd4Zs0fOus1MjmVQ4P7A5FgGpcSRmRRH//josFv8TIEuIkGvs66+eN8h9lTVUnqgltKqWkqr69hTXUtJ5SFW7thH5aGG494zJiriaNgPTI4LhH7rHwTeY/1iQudMWgW6iIS0lH7RpAxNYfzQlA63qW1oovxAHaXVLWFfVl3LnupaSqtr2bCrmjc3lnG4oem41ybFRR3t8DOPC32v409PjA2KHbgKdBEJe3HRkUePse+Ic46ausaW0G+n49+2dS9lB+pobG57YSA7OuZp6fgzk+IYlBLbqvuPY0APj3kU6CIieMslJMVFkxQXfdzSxq01N3vr5JQGuvtjO/6d+2tZVbSffQfrj3ttTGQEA5NjuXlWLl8/b0S3fw8KdBGRkxARYWQkxZKRFHvCMU9d4zFjnlYd/8Dk2B6pTYEuItIDYqMiyRoQT9aAjsc83a1LU3wzu9jMNplZgZnd087z882s3MzWBG7/0v2liojIiXTaoZtZJPAwcCFQAqwws5edcxuO2fQPzrlv9UCNIiLSBV3p0KcDBc65bc65emAxMLdnyxIRkZPVlUAfChS3+rok8NixvmRm68zseTPL7pbqRESky7rrSPg/A7nOuYnA34En2tvIzG4xs3wzyy8vL++mjxYREehaoO8EWnfcWYHHjnLOVTjn6gJf/haY2t4bOecWOufynHN5GRkZp1KviIh0oCuBvgIYbWbDzSwGuBZ4ufUGZja41ZefBzZ2X4kiItIVnR7l4pxrNLNvAX8DIoHfOefWm9mPgXzn3MvAHWb2eaAR2AfM78GaRUSkHeac63yrnvhgs3Jgxym+PB3Y243l9LRQqjeUaoXQqjeUaoXQqjeUaoXTq3eYc67dmbVvgX46zCzfOZfndx1dFUr1hlKtEFr1hlKtEFr1hlKt0HP1+r/eo4iIdAsFuohImAjVQF/odwEnKZTqDaVaIbTqDaVaIbTqDaVaoYfqDckZuoiIHC9UO3QRETmGAl1EJEyEXKB3tjZ7MDGz35lZmZl97HctnTGzbDN7y8w2mNl6M1vgd00dMbM4M/vQzNYGav2R3zV1hZlFmtlqM3vF71pOxMwKzeyjwLUN8v2upzNm1j+wKOAnZrbRzGb5XVN7zGxMq2tGrDGzajO7s1s/I5Rm6IG12TfTam12YF47a7MHBTM7D6gBnnTOjfe7nhMJLN8w2Dm3ysySgJXAF4Lx79a8q+wmOOdqzCwaeBdY4Jz7wOfSTsjMvgvkAcnOucv9rqcjZlYI5DnnQuJEHTN7AljqnPttYHmSeOfcfr/rOpFAlu0EZjjnTvUEy+OEWoceUmuzO+fewVsKIeg553Y751YF7h/AW4+nvWWSfec8NYEvowO3oO5MzCwLuAxv8TrpJmaWApwHPAbgnKsP9jAPuADY2p1hDqEX6F1dm11Og5nlApOB5f5W0rHA+GINUAb83TkXtLUGPADcDTT7XUgXOOB1M1tpZrf4XUwnhgPlwO8D46zfmlmC30V1wbXAou5+01ALdOlhZpYILAHudM5V+11PR5xzTc65s/GWc55uZkE70jKzy4Ey59xKv2vpok8556YAlwDfDIwOg1UUMAV4xDk3GTgIBPu+tRi8VWn/2N3vHWqB3una7HLqAvPoJcAzzrkX/K6nKwK/Xr8FXOx3LScwG/h8YDa9GPiMmT3tb0kdc87tDPxZBryIN+oMViVASavf0J7HC/hgdgmwyjlX2t1vHGqB3una7HJqAjsaHwM2Oud+4Xc9J2JmGWbWP3C/H95O8k/8rapjzrl/c85lOedy8f7Nvumcu8HnstplZgmBneIERhefA4L2KC3n3B6g2MzGBB66AAi6HfnHmEcPjFugC+uhB5OO1mb3uawOmdkiYA6QbmYlwA+dc4/5W1WHZgM3Ah8FZtMA9zrn/upjTR0ZDDwROFIgAnjOORfUhwKGkEzgRe/nO1HAs8651/wtqVPfBp4JNHnbgK/4XE+HAj8kLwS+0SPvH0qHLYqISMdCbeQiIiIdUKCLiIQJBbqISJhQoIuIhAkFuohImFCgi4iECQW6iEiY+P/E2F+Z2iB4WQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FLc7pyqqXmF"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_nmGC1SSyzB"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1EwwcBmVz-Z"
      },
      "source": [
        "def get_pred(model,feature):\r\n",
        "  with torch.no_grad():\r\n",
        "    pred = model(feature.float().cuda())\r\n",
        "\r\n",
        "  pred = pred.cpu()\r\n",
        "  pred = np.array(pred)\r\n",
        "  pred = np.argmax(pred,1)\r\n",
        "\r\n",
        "  return pred \r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2DF_Hk3WXXh"
      },
      "source": [
        "train_pred = get_pred(net,train_x)\r\n",
        "val_pred   = get_pred(net,val_x)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC0pUDeeW9pY",
        "outputId": "ed681e1e-578b-4ad4-a584-263e9e8c950f"
      },
      "source": [
        "print(classification_report(train_y, train_pred))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83       144\n",
            "           1       0.84      0.62      0.71       144\n",
            "           2       0.90      0.71      0.80       186\n",
            "           3       0.76      0.98      0.86       192\n",
            "           4       0.89      0.65      0.75       192\n",
            "           5       0.39      0.97      0.56       197\n",
            "           6       0.81      0.37      0.51       197\n",
            "           7       0.70      0.61      0.65       197\n",
            "           8       0.51      0.19      0.28       197\n",
            "           9       0.36      0.48      0.41       197\n",
            "          10       0.79      0.97      0.87       224\n",
            "          11       0.94      0.54      0.69       224\n",
            "          12       0.80      1.00      0.89       224\n",
            "\n",
            "    accuracy                           0.68      2515\n",
            "   macro avg       0.74      0.68      0.68      2515\n",
            "weighted avg       0.74      0.68      0.68      2515\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZzw8hk-Xxoc",
        "outputId": "9abdca93-7948-461a-bf57-40371472258b"
      },
      "source": [
        "print(classification_report(val_y, val_pred))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.36      0.47        45\n",
            "           1       0.17      0.07      0.10        45\n",
            "           2       0.70      0.69      0.70        45\n",
            "           3       0.43      0.67      0.52        45\n",
            "           4       0.00      0.00      0.00        45\n",
            "           5       0.20      0.38      0.26        45\n",
            "           6       0.20      0.27      0.23        45\n",
            "           7       0.17      0.29      0.21        45\n",
            "           8       0.00      0.00      0.00        45\n",
            "           9       0.00      0.00      0.00        45\n",
            "          10       0.38      0.91      0.54        45\n",
            "          11       0.12      0.02      0.04        45\n",
            "          12       0.55      0.36      0.43        45\n",
            "\n",
            "    accuracy                           0.31       585\n",
            "   macro avg       0.28      0.31      0.27       585\n",
            "weighted avg       0.28      0.31      0.27       585\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2pH_cuKWlqY"
      },
      "source": [
        "confusion_matrix(train_y, train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1awmWQ_jWm2C"
      },
      "source": [
        "confusion_matrix(val_y, val_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}