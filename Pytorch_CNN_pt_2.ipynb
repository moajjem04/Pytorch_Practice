{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch CNN pt 2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3cAo/AJux88C9ewz3Qh74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moajjem04/Pytorch_Practice/blob/main/Pytorch_CNN_pt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSx1fZFIhY61"
      },
      "source": [
        "# Downloading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRCC-tmlhbrc"
      },
      "source": [
        "## Installing `wget`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPa2XLCGeDgW"
      },
      "source": [
        "%%capture\r\n",
        "!pip install wget"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fLGhvw3hdzc"
      },
      "source": [
        "## Downloading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PsUMU3c0JH"
      },
      "source": [
        "import wget\r\n",
        "url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\r\n",
        "filename = wget.download(url,'data.zip') # the file will be saved as data.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj3pX-yNhf0F"
      },
      "source": [
        "## Unzipping the data into `PetImages` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EjI6AxAfSIJ"
      },
      "source": [
        "%%capture\r\n",
        "!unzip '/content/data.zip' -d '/content/';"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue21Gn083KqX"
      },
      "source": [
        "# Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKB1XVgRlOKc"
      },
      "source": [
        "## Importing Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qE2up3Ihsg9"
      },
      "source": [
        "import os\r\n",
        "import cv2 as cv\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDeWEFa2lSsJ"
      },
      "source": [
        "## Preprocessing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAm7Woj8lYWz"
      },
      "source": [
        "`REBUILD_DATA` is used as a flag in this instance. This is because, ideally, we would want to preprocess(resize, augment, etc.) once. Then we will set `REBUILD_DATA`to `False`. This is true in most cases as there is usually a lot of data and data cleaning and preprocessing takes a bunch of time. So to run it every time we do an experiment would be a waste of resources on an already resource intensive task. But in this case, I have decided to not save the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj22I4dvnXhO"
      },
      "source": [
        "REBUILD_DATA = True\r\n",
        "\r\n",
        "class DogsVSCats():\r\n",
        "  IMG_SIZE = 50\r\n",
        "  CATS = 'PetImages/Cat'\r\n",
        "  DOGS = 'PetImages/Dog'\r\n",
        "  labels = {CATS:0, DOGS:1}\r\n",
        "  training_data = []\r\n",
        "  cat_count = 0\r\n",
        "  dog_count = 0\r\n",
        "\r\n",
        "  def make_training_data(self):\r\n",
        "    for label in self.labels:\r\n",
        "      print('\\n',label)\r\n",
        "      for f in tqdm(os.listdir(label)):\r\n",
        "        try:\r\n",
        "          path = os.path.join(label,f)\r\n",
        "          img = cv.imread(path, cv.IMREAD_GRAYSCALE)\r\n",
        "          img = cv.resize(img,(self.IMG_SIZE,self.IMG_SIZE))\r\n",
        "          self.training_data.append([np.array(img),np.eye(2)[self.labels[label]]])\r\n",
        "\r\n",
        "          if label == self.CATS:\r\n",
        "            self.cat_count += 1\r\n",
        "          elif label == self.DOGS:\r\n",
        "            self.dog_count += 1\r\n",
        "        except Exception as e:\r\n",
        "          #print(label, f, str(e))\r\n",
        "          pass\r\n",
        "    print('\\n')  \r\n",
        "    print('Cats:',self.cat_count)\r\n",
        "    print('Dogs:',self.dog_count) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11pcjqXMnWYJ"
      },
      "source": [
        "Since `REBUILD_DATA` is `True`, the preprocessing will take place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIUd3uO6xhfe",
        "outputId": "19312c8a-3d0a-4712-e23f-91a4bde6f209"
      },
      "source": [
        "if REBUILD_DATA:\r\n",
        "  dogvcat = DogsVSCats()\r\n",
        "  dogvcat.make_training_data()\r\n",
        "  training_data = dogvcat.training_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 66/12501 [00:00<00:18, 659.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " PetImages/Cat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12501/12501 [00:12<00:00, 1003.65it/s]\n",
            "  1%|          | 102/12501 [00:00<00:12, 1016.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " PetImages/Dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12501/12501 [00:13<00:00, 942.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Cats: 12476\n",
            "Dogs: 12470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSedrSFHp5Dp"
      },
      "source": [
        "Inspecting the `training_data` by looking at the length of the list and a sample data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHLEbBbq0D1G",
        "outputId": "cc8c7095-c2e8-47d3-f61f-2a93205f7807"
      },
      "source": [
        "len(training_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNWq_hgVzphl",
        "outputId": "0cdf89c6-563f-497b-e838-bfccde3596d1"
      },
      "source": [
        "training_data[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[34, 35, 34, ..., 56, 57, 61],\n",
              "        [35, 36, 36, ..., 69, 68, 66],\n",
              "        [35, 37, 39, ..., 63, 76, 75],\n",
              "        ...,\n",
              "        [38, 34, 33, ..., 44, 52, 53],\n",
              "        [33, 72, 48, ..., 47, 50, 48],\n",
              "        [31, 34, 28, ..., 59, 53, 52]], dtype=uint8), array([1., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk-CI6xdqCCJ"
      },
      "source": [
        "### Shuffle the data so that bias inserted into the network is minimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NnWmrp2yF6M"
      },
      "source": [
        "np.random.shuffle(training_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-gLM6A83Pft"
      },
      "source": [
        "# Neural Network with CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z0ByynJ30ie"
      },
      "source": [
        "## Importing Libraries for NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5udv8IdG3OKl"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk5LeAjYSzeK"
      },
      "source": [
        "## Checking the NN shapes on a dummy network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B_Ks8v9SRIJ"
      },
      "source": [
        "### Printing the shape of the output of each layer before defining the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7yNtZH2r0cJ",
        "outputId": "6f4f42c8-ff1e-4758-bd7d-067e8597245a"
      },
      "source": [
        "inp_size = 50; \r\n",
        "\r\n",
        "m1 = nn.Conv2d(1,32,5)\r\n",
        "m2 = nn.Conv2d(32,64,5)\r\n",
        "m3 = nn.Conv2d(64,128,5)\r\n",
        "m0 = nn.Flatten()\r\n",
        "\r\n",
        "input = torch.randn(1, 1, inp_size, inp_size)\r\n",
        "print('Input Shape:',input.shape)\r\n",
        "\r\n",
        "output = F.relu(m1(input))\r\n",
        "print('Output after 1st Conv:',output.shape)\r\n",
        "output = F.max_pool2d(output,(2, 2))\r\n",
        "print('Output after 1st MaxPool:',output.shape)\r\n",
        "\r\n",
        "output = F.relu(m2(output))\r\n",
        "print('Output after 2nd Conv:',output.shape)\r\n",
        "output = F.max_pool2d(output,(2, 2))\r\n",
        "print('Output after 2nd MaxPool:',output.shape)\r\n",
        "\r\n",
        "output = F.relu(m3(output))\r\n",
        "print('Output after 3rd Conv:',output.shape)\r\n",
        "output = F.max_pool2d(output,(2, 2))\r\n",
        "print('Output after 3rd MaxPool:',output.shape)\r\n",
        "\r\n",
        "output = m0(output)\r\n",
        "print('Flat:',output.shape)\r\n",
        "#print(128 * calc_shape(inp_size,kernel,stride_size,padding))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape: torch.Size([1, 1, 50, 50])\n",
            "Output after 1st Conv: torch.Size([1, 32, 46, 46])\n",
            "Output after 1st MaxPool: torch.Size([1, 32, 23, 23])\n",
            "Output after 2nd Conv: torch.Size([1, 64, 19, 19])\n",
            "Output after 2nd MaxPool: torch.Size([1, 64, 9, 9])\n",
            "Output after 3rd Conv: torch.Size([1, 128, 5, 5])\n",
            "Output after 3rd MaxPool: torch.Size([1, 128, 2, 2])\n",
            "Flat: torch.Size([1, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyNu8sKlSdFZ"
      },
      "source": [
        "### Using a function to check the final size of the flattened layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GrLKdYdnMgR",
        "outputId": "719fa9e4-df31-49fe-9873-a87f1df351e4"
      },
      "source": [
        "import math\r\n",
        "def calc_shape(inp,kernel,stride,dilation,padding):\r\n",
        "  out = (inp + 2*padding - dilation*(kernel-1) -1)/stride + 1\r\n",
        "  #out = round(out)\r\n",
        "  out = math.floor(out)\r\n",
        "  return out\r\n",
        "\r\n",
        "input = torch.randn(1, 1, inp_size, inp_size)\r\n",
        "print('Input Shape:',input.shape[-1])\r\n",
        "\r\n",
        "temp = calc_shape(50,5,1,1,0)\r\n",
        "print('After Conv1:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool1:',temp)\r\n",
        "\r\n",
        "temp = calc_shape(temp,5,1,1,0)\r\n",
        "print('After Conv2:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool2:',temp)\r\n",
        "\r\n",
        "temp = calc_shape(temp,5,1,1,0)\r\n",
        "print('After Conv3:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool3:',temp)\r\n",
        "\r\n",
        "# The final convolution layer has 128 channels so the output is multiplied by 128\r\n",
        "print('Flattened Size:',temp*temp*128 )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape: 50\n",
            "After Conv1: 46\n",
            "After MaxPool1: 23\n",
            "After Conv2: 19\n",
            "After MaxPool2: 9\n",
            "After Conv3: 5\n",
            "After MaxPool3: 2\n",
            "Flattened Size: 512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hN6krbcq8XC"
      },
      "source": [
        "### Explaining the shape of the flattened layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXw7eVdxS8k4"
      },
      "source": [
        "The initial size of the data is of `(1,1,50,50)`. The numbers are explained below:\r\n",
        "* the 1st `1` denotes the no of samples\r\n",
        "* the 2nd `1` denotes the no of channels\r\n",
        "* the `50` represents the dimension of the image, i.e. a `50x50` image.\r\n",
        "\r\n",
        "With each convolution, the no of channels increases while the size of the data decreases. This is by design. # Include appropriate discussion \\\r\n",
        "\\\r\n",
        "The size of the data also decreases when pooling is used (in our case max pooling). The output after a convolution and pooling follow this general formula assuming that the input data is square:\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "Size_{Out} = \\frac{Size_{In} + 2 * Padding - Dilation * (Kernel - 1) -1}{Stride} + 1 \\tag{1}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "Here:\r\n",
        "* $Size_{Out}$ is the size of the output matrix\r\n",
        "* $Size_{In}$ is the size of the input matrix \r\n",
        "* $Padding$ is the padding size. It defaults to `0`\r\n",
        "* $Dilation$ is a parameter that controls the stride of elements in the window. It defaults to `1`\r\n",
        "* $Kernel$ is the kernel size.\r\n",
        "* $Stride$ is the length of stride of the kernel. It defaults to the kernel size.\r\n",
        "\r\n",
        "We ran our dummy model. Then we printed the outputs after each convolution and pooling. \r\n",
        "```\r\n",
        "Input Shape: torch.Size([1, 1, 50, 50])\r\n",
        "Output after 1st Conv: torch.Size([1, 32, 46, 46])\r\n",
        "Output after 1st MaxPool: torch.Size([1, 32, 23, 23])\r\n",
        "Output after 2nd Conv: torch.Size([1, 64, 19, 19])\r\n",
        "Output after 2nd MaxPool: torch.Size([1, 64, 9, 9])\r\n",
        "Output after 3rd Conv: torch.Size([1, 128, 5, 5])\r\n",
        "Output after 3rd MaxPool: torch.Size([1, 128, 2, 2])\r\n",
        "Flattened Layer: torch.Size([1, 512])\r\n",
        "```\r\n",
        "The size of the flattened layer is something that is not easily retrieved from code. Most tutorials enter the size to a fully connected layer(a usual next step after conv layers) without justifying the numbers. I will try to use the formula according to Equation (1) to get the same number that we recieved from simulating a dummy network. \\\r\n",
        "We will use the following function to calculate the size:\r\n",
        "```python\r\n",
        "def calc_shape(inp,kernel,stride,dilation,padding):\r\n",
        "  out = (inp + 2*padding - dilation*(kernel-1) -1)/stride + 1\r\n",
        "  out = math.floor(out)\r\n",
        "  return out\r\n",
        "```\r\n",
        "The code is just the equation (1) in code form. The output is rounded down.\r\n",
        "The function is used as below:\r\n",
        "\r\n",
        "```python\r\n",
        "input = torch.randn(1, 1, inp_size, inp_size)\r\n",
        "print('Input Shape:',input.shape[-1])\r\n",
        "\r\n",
        "temp = calc_shape(50,5,1,1,0)\r\n",
        "print('After Conv1:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool1:',temp)\r\n",
        "\r\n",
        "temp = calc_shape(temp,5,1,1,0)\r\n",
        "print('After Conv2:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool2:',temp)\r\n",
        "\r\n",
        "temp = calc_shape(temp,5,1,1,0)\r\n",
        "print('After Conv3:',temp)\r\n",
        "temp = calc_shape(temp,2,2,1,0)\r\n",
        "print('After MaxPool3:',temp)\r\n",
        "\r\n",
        "print('Flattened Size:',temp*temp*128 )\r\n",
        "```\r\n",
        "The size from the final layer of Max Pooling is squared and multiplied by `128`. That is the number of channels according to our dummy model. So when the data is flattened we get `temp*temp*128`.\r\n",
        "And we get the output:\r\n",
        "```\r\n",
        "Input Shape: 50\r\n",
        "After Conv1: 46\r\n",
        "After MaxPool1: 23\r\n",
        "After Conv2: 19\r\n",
        "After MaxPool2: 9\r\n",
        "After Conv3: 5\r\n",
        "After MaxPool3: 2\r\n",
        "Flattened Size: 512\r\n",
        "```\r\n",
        "We can see that the values calculated by us match that of the dummy simulation. This method can be used before hand if we want to know the size of the flattened layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NUnsmHn3_p9"
      },
      "source": [
        "## Defining the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZjxR7_q4Com"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    # Layer definition\r\n",
        "    self.conv1 = nn.Conv2d(1,32,5)\r\n",
        "    self.conv2 = nn.Conv2d(32,64,5)\r\n",
        "    self.conv3 = nn.Conv2d(64,128,5)\r\n",
        "    # This code is used calculate the size of the flattened layer by having one\r\n",
        "    #   pass forward\r\n",
        "    x = torch.randn(50,50).view(-1,1,50,50)\r\n",
        "    self._to_linear = None\r\n",
        "    self.convs(x)\r\n",
        "\r\n",
        "    self.flat = nn.Flatten()\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\r\n",
        "    self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\r\n",
        "\r\n",
        "  def convs(self, x):\r\n",
        "    # max pooling over 2x2\r\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\r\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\r\n",
        "    #print(x[0].shape)\r\n",
        "\r\n",
        "    if self._to_linear is None:\r\n",
        "      self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\r\n",
        "    return x\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.convs(x)\r\n",
        "    x = self.flat(x)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = self.fc2(x) # bc this is our output layer. No activation here.\r\n",
        "    return F.softmax(x, dim=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7_tThuCR5bM"
      },
      "source": [
        "## Initializing the model and viewing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8vb4EvmvSr4",
        "outputId": "7d6b140c-11b7-4048-97eb-fa9eefa75808"
      },
      "source": [
        "net = Net()\r\n",
        "print(net)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFwhr_cMv2de"
      },
      "source": [
        "## Optimizers and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsUPrFsVv4RF"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "optimizer = optim.Adam(net.parameters(),lr = 1e-3)\r\n",
        "loss_function = nn.MSELoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxHJUWYErIEC"
      },
      "source": [
        "### Splitting the data into feature set (`X`) and label(`y`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAVXeD-Swa-G"
      },
      "source": [
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\r\n",
        "X = X/255.0\r\n",
        "\r\n",
        "y = torch.Tensor([i[1] for i in training_data])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtHeRSHUrUER"
      },
      "source": [
        "### Splitting the data into validation and train set using `val_pct` as the ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foeEKPNaxRHu",
        "outputId": "3f35b757-e744-4ae3-a23c-6e83583260c8"
      },
      "source": [
        "val_pct = 0.1\r\n",
        "val_size = int(len(X) * val_pct)\r\n",
        "print(val_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mbaCl4Nx1GL"
      },
      "source": [
        "Just a simple way of valid/train split. This is okay as the images are already shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aANzbdMxmJV"
      },
      "source": [
        "train_X = X[:-val_size]\r\n",
        "train_y = y[:-val_size]\r\n",
        "\r\n",
        "test_X = X[-val_size:]\r\n",
        "test_y = y[-val_size:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmjKT0DLy_os",
        "outputId": "5c8e8622-8083-4851-dc32-f619acaa48f9"
      },
      "source": [
        "print(len(train_y))\r\n",
        "print(len(test_y))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22452\n",
            "2494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruNcwQrcrd3J"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB_KQw4yrp6q"
      },
      "source": [
        "Training for 1 epoch. Also training in batches as training all of the data at a time would be tough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKmNYkNCzIhM"
      },
      "source": [
        "batch_size = 100\r\n",
        "epochs = 3\r\n",
        "for epoch in range(epochs):\r\n",
        "  for i in tqdm(range(0,len(train_X),batch_size)):\r\n",
        "    #print('\\n',i,i+batch_size)\r\n",
        "    batch_X = train_X[i:i+batch_size].view(-1,1,50,50)\r\n",
        "    batch_y = train_y[i:i+batch_size]\r\n",
        "\r\n",
        "    net.zero_grad() # or optimizer.zero_grad()\r\n",
        "    outputs = net(batch_X)\r\n",
        "    loss = loss_function(outputs,batch_y)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "  print(loss)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2p2_5-01ss9"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFjjIvq71uDN",
        "outputId": "637fa257-d61c-4e94-987a-b91ca7b60933"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "with torch.no_grad():\r\n",
        "    for i in tqdm(range(len(test_X))):\r\n",
        "        real_class = torch.argmax(test_y[i])\r\n",
        "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \r\n",
        "        predicted_class = torch.argmax(net_out)\r\n",
        "\r\n",
        "        if predicted_class == real_class:\r\n",
        "            correct += 1\r\n",
        "        total += 1\r\n",
        "print(\"\\nAccuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:05<00:00, 497.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:  0.658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRmRKULDueID"
      },
      "source": [
        "# Neural Network with GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVL4sRPMuiyi",
        "outputId": "50ff50b3-5ce3-4b1f-bfa5-da273ee17bec"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gcdaMcIvwd7",
        "outputId": "1739474c-50e0-4949-d6d2-df40ed23df10"
      },
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAzKXmIL0z7k"
      },
      "source": [
        "Lets define a new network creatively named `net_gpu`. We will initialize it like normal and then assign it to CUDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNfyxAGQzIz0"
      },
      "source": [
        "net_gpu = Net()\r\n",
        "optimizer = optim.Adam(net.parameters(),lr = 1e-3)\r\n",
        "loss_function = nn.MSELoss()\r\n",
        "if torch.cuda.is_available():\r\n",
        "  net_gpu = net_gpu.cuda()\r\n",
        "  loss_function = loss_function.cuda()\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjvqkAl110xL",
        "outputId": "802daec9-9239-4fc7-fb2d-1b4d9e9146d5"
      },
      "source": [
        "net_gpu"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjBlUCfj2Bfs"
      },
      "source": [
        "The train and test set have already been splitted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUBOUYmG2FpE",
        "outputId": "d0836330-bcdf-4806-d44e-668028f01a52"
      },
      "source": [
        "print('Shape of training feature set:',train_X.shape)\r\n",
        "print('Shape of training label      :',train_y.shape)\r\n",
        "print('Shape of testing feature set :',test_X.shape)\r\n",
        "print('Shape of testing label       :',test_y.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training feature set: torch.Size([22452, 50, 50])\n",
            "Shape of training label      : torch.Size([22452, 2])\n",
            "Shape of testing feature set : torch.Size([2494, 50, 50])\n",
            "Shape of testing label       : torch.Size([2494, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIfcuCkd1wF2"
      },
      "source": [
        "Defining a training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds1a-Jf72eDU"
      },
      "source": [
        "def train_model(train_X,train_y,batch_size):\r\n",
        "  for i in range(0,len(train_y),batch_size):\r\n",
        "    net_gpu.train()\r\n",
        "    #print('\\n',i,i+batch_size)\r\n",
        "    batch_X = train_X[i:i+batch_size].view(-1,1,50,50)\r\n",
        "    batch_y = train_y[i:i+batch_size]\r\n",
        "\r\n",
        "    if torch.cuda.is_available():\r\n",
        "      batch_X = batch_X.cuda()\r\n",
        "      batch_y = batch_y.cuda()\r\n",
        "\r\n",
        "    net_gpu.zero_grad() # or optimizer.zero_grad()\r\n",
        "    outputs = net_gpu(batch_X)\r\n",
        "    loss = loss_function(outputs,batch_y)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "  print('\\nLoss :',loss)\r\n",
        "  #return loss\r\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB__3X_33muu"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmYbnHMg3pa0",
        "outputId": "61598e05-d35c-495a-bdee-d09a3b98c58c"
      },
      "source": [
        "batch_size = 100;\r\n",
        "loss =0;\r\n",
        "epochs = 5\r\n",
        "for epoch in tqdm(range(epochs)):\r\n",
        "  \r\n",
        "  loss = train_model(train_X,train_y,batch_size)\r\n",
        "  print('\\nEpoch:',epoch)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.98s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss : tensor(0.2505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 40%|████      | 2/5 [00:03<00:05,  1.95s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss : tensor(0.2505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 3/5 [00:05<00:03,  1.94s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss : tensor(0.2505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 4/5 [00:07<00:01,  1.92s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss : tensor(0.2505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 5/5 [00:09<00:00,  1.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loss : tensor(0.2505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "\n",
            "Epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ6WoM5L92-F"
      },
      "source": [
        "def test(model):\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  with torch.no_grad():\r\n",
        "      for i in tqdm(range(len(test_X))):\r\n",
        "          real_class = torch.argmax(test_y[i]).cuda()\r\n",
        "          new_test = test_X[i].view(-1, 1, 50, 50)\r\n",
        "          net_out = model(new_test.cuda())[0]  # returns a list, \r\n",
        "          predicted_class = torch.argmax(net_out)\r\n",
        "\r\n",
        "          if predicted_class == real_class:\r\n",
        "              correct += 1\r\n",
        "          total += 1\r\n",
        "  print(\"\\nAccuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYxOfKTX-Soe",
        "outputId": "4f9bfa01-4488-4fe3-fd01-33e3041e7ca9"
      },
      "source": [
        "test(net_gpu)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:01<00:00, 1516.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy:  0.513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}